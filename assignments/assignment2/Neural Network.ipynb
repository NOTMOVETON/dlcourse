{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"../../data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for w1\n",
      "Gradient check passed!\n",
      "Checking gradient for w2\n",
      "Gradient check passed!\n",
      "Checking gradient for b1\n",
      "Gradient check passed!\n",
      "Checking gradient for b2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for w1\n",
      "Gradient check passed!\n",
      "Checking gradient for w2\n",
      "Gradient check passed!\n",
      "Checking gradient for b1\n",
      "Gradient check passed!\n",
      "Checking gradient for b2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.301004, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302046, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302020, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302829, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302121, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302322, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302105, Train accuracy: 0.114222, val accuracy: 0.147000\n",
      "Loss: 2.302548, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302534, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302898, Train accuracy: 0.114222, val accuracy: 0.147000\n",
      "Loss: 2.302365, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302843, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300734, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301734, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301940, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302110, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303063, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2dd056fc1c0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.318126, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.324036, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.336877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312723, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269800, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238607, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264151, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.335841, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252673, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297973, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237056, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201364, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293530, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264892, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270953, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.360514, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210671, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.326824, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273976, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.319307, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.322443, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263108, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298041, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295488, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301756, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295503, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281027, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292290, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307537, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273771, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278122, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261987, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235108, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.340198, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281818, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283882, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.335738, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.320542, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.332754, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.281658, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.293447, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.305892, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.336132, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.280302, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.283314, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.241938, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.041604, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.955679, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.596983, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.098300, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.880894, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.771536, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.395213, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.284027, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.573697, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.025960, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.569521, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.428408, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.833313, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.475478, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.230051, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.817895, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.427157, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.830274, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.411147, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.663745, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.839950, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.241866, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.038323, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.966023, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.106896, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.744617, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.569718, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.098353, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.706175, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.919851, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 2.015580, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.611320, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.816897, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.899937, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.092100, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.625375, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.693379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.638787, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.826651, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.346194, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.442347, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.557477, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.547444, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.030406, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.433627, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.651652, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.038005, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.601475, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.218782, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.208324, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.456453, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.165264, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.441678, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647909, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.249818, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.631549, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.299927, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.985124, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.952840, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.339579, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.869590, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.635224, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.638307, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.590561, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.317051, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.577163, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.580478, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.335753, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.266600, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.601903, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.961404, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.321742, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.045785, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.518883, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.326475, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.764562, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.554416, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.148813, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.296730, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.328705, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.704808, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.233548, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.075459, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.496978, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.499416, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.104258, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.385010, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.588176, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.294435, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.098950, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.393818, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.336367, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.148558, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.688127, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.212986, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.207854, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.208386, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.529944, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.092172, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.325101, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.261021, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.318570, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.155004, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.332892, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.402500, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.224852, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.557465, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.398652, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263280, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.451032, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.469137, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.351304, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.178948, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.106081, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.378770, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.162889, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.122162, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.255156, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.227546, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219853, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.372320, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.205831, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.082531, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.568287, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.374564, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.386135, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.410904, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.490287, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.319655, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.353822, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.259074, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.121651, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.132036, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.430936, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.419862, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.359021, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.177139, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.142865, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406840, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.258317, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.348143, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.302351, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.238445, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.193072, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.007798, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.114472, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.477919, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.833902, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 2.367405, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.369185, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.474017, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.341211, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.522477, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 2.213195, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.999163, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 2.599418, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 3.164965, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 2.264320, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 2.342375, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.708419, Train accuracy: 1.000000, val accuracy: 0.066667\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(0.2), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycle 1...\n",
      "Loss: 1.942140, Train accuracy: 0.341000, val accuracy: 0.350000\n",
      "Loss: 1.187935, Train accuracy: 0.536556, val accuracy: 0.527000\n",
      "Loss: 1.120921, Train accuracy: 0.612778, val accuracy: 0.608000\n",
      "Loss: 1.329141, Train accuracy: 0.670556, val accuracy: 0.657000\n",
      "Loss: 0.840274, Train accuracy: 0.690667, val accuracy: 0.644000\n",
      "Loss: 1.081798, Train accuracy: 0.732111, val accuracy: 0.700000\n",
      "Loss: 0.778580, Train accuracy: 0.751000, val accuracy: 0.705000\n",
      "Loss: 0.751482, Train accuracy: 0.776222, val accuracy: 0.708000\n",
      "Loss: 0.779967, Train accuracy: 0.797000, val accuracy: 0.714000\n",
      "Loss: 0.865790, Train accuracy: 0.790333, val accuracy: 0.706000\n",
      "\n",
      "Cycle 2...\n",
      "Loss: 2.299718, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301915, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291867, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297373, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292252, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295963, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287436, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293917, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270539, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 3...\n",
      "Loss: 2.285749, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288601, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265138, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236577, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.206824, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240543, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287682, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183651, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 4...\n",
      "Loss: 2.289481, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267915, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253066, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260665, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227853, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193014, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227517, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177601, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204838, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 5...\n",
      "Loss: 2.284258, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280626, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241289, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299879, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198987, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258049, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257085, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215358, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290752, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 6...\n",
      "Loss: 2.301442, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297956, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298399, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294312, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293496, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292349, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282809, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281548, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281447, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 7...\n",
      "Loss: 2.284121, Train accuracy: 0.284778, val accuracy: 0.295000\n",
      "Loss: 2.307840, Train accuracy: 0.424222, val accuracy: 0.413000\n",
      "Loss: 2.264851, Train accuracy: 0.387556, val accuracy: 0.386000\n",
      "Loss: 2.155972, Train accuracy: 0.387111, val accuracy: 0.413000\n",
      "Loss: 2.237291, Train accuracy: 0.399333, val accuracy: 0.390000\n",
      "Loss: 2.026314, Train accuracy: 0.385778, val accuracy: 0.400000\n",
      "Loss: 2.199734, Train accuracy: 0.410889, val accuracy: 0.403000\n",
      "Loss: 2.051547, Train accuracy: 0.426778, val accuracy: 0.444000\n",
      "Loss: 2.099354, Train accuracy: 0.432889, val accuracy: 0.442000\n",
      "Loss: 1.891609, Train accuracy: 0.405556, val accuracy: 0.391000\n",
      "\n",
      "Cycle 8...\n",
      "Loss: 2.299085, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273592, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270496, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275267, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305833, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221488, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245378, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191875, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 9...\n",
      "Loss: 2.296388, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287267, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269560, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161535, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286100, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277543, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.118760, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248532, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.113492, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.232686, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 10...\n",
      "Loss: 2.300344, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297595, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294123, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297371, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297922, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300587, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293866, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292695, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 11...\n",
      "Loss: 2.301056, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264050, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230690, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281601, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282701, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220838, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254841, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181761, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 12...\n",
      "Loss: 1.834417, Train accuracy: 0.422333, val accuracy: 0.408000\n",
      "Loss: 1.845787, Train accuracy: 0.567222, val accuracy: 0.572000\n",
      "Loss: 0.945057, Train accuracy: 0.629000, val accuracy: 0.608000\n",
      "Loss: 1.685196, Train accuracy: 0.622111, val accuracy: 0.592000\n",
      "Loss: 1.672546, Train accuracy: 0.635444, val accuracy: 0.595000\n",
      "Loss: 1.462631, Train accuracy: 0.678889, val accuracy: 0.648000\n",
      "Loss: 1.413091, Train accuracy: 0.696556, val accuracy: 0.659000\n",
      "Loss: 1.383589, Train accuracy: 0.682444, val accuracy: 0.614000\n",
      "Loss: 1.472430, Train accuracy: 0.699111, val accuracy: 0.641000\n",
      "Loss: 2.273321, Train accuracy: 0.728556, val accuracy: 0.639000\n",
      "\n",
      "Cycle 13...\n",
      "Loss: 2.214479, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216009, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.144033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.067461, Train accuracy: 0.248778, val accuracy: 0.258000\n",
      "Loss: 2.010834, Train accuracy: 0.333667, val accuracy: 0.337000\n",
      "Loss: 1.570068, Train accuracy: 0.396000, val accuracy: 0.390000\n",
      "Loss: 1.826131, Train accuracy: 0.485444, val accuracy: 0.475000\n",
      "Loss: 1.429210, Train accuracy: 0.546667, val accuracy: 0.546000\n",
      "Loss: 1.284771, Train accuracy: 0.595889, val accuracy: 0.603000\n",
      "Loss: 1.059006, Train accuracy: 0.634333, val accuracy: 0.627000\n",
      "\n",
      "Cycle 14...\n",
      "Loss: 2.290688, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242963, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261929, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240048, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299233, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213724, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.158093, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241466, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253669, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "\n",
      "Cycle 15...\n",
      "Loss: 2.301949, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297911, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298332, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293979, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297103, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295374, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292308, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280913, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290983, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "n_iterations = 15\n",
    "num_epochs = 10\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "reg_strength = [1e-6, 1e-4, 1e-2]\n",
    "learning_rate_decay = [0.888, 0.995, 0.999]\n",
    "hidden_layer_size = [64, 128, 256]\n",
    "batch_size = [64]\n",
    "momentums = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "for i in range(0, n_iterations):    \n",
    "    lr = choice(learning_rates)\n",
    "    reg = choice(reg_strength)\n",
    "    lrd = choice(learning_rate_decay)\n",
    "    hs = choice(hidden_layer_size)\n",
    "    bs = choice(batch_size)\n",
    "    momentum = choice(momentums)\n",
    "    \n",
    "    model = TwoLayerNet(n_input=train_X.shape[1], n_output=10,\n",
    "                        hidden_layer_size=hs, reg=reg)\n",
    "    dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "    trainer = Trainer(model, dataset, MomentumSGD(momentum=momentum), learning_rate=lr,\n",
    "                      learning_rate_decay=lrd, num_epochs=num_epochs, batch_size=bs)\n",
    "    \n",
    "    print()\n",
    "    print (\"Cycle {}...\".format(i+1))\n",
    "    loss_hist, train_hist, val_hist = trainer.fit()\n",
    "    \n",
    "    if val_hist[-1] > best_val_accuracy:\n",
    "        best_val_accuracy = val_hist[-1]\n",
    "        best_classifier = model\n",
    "        \n",
    "        best_params['learning_rate'] = lr\n",
    "        best_params['reg_strength'] = reg\n",
    "        best_params['learning_rate_decay'] = lrd\n",
    "        best_params['hidden_layer_size'] = hs\n",
    "        best_params['batch_size'] = bs\n",
    "        best_params['momentum'] = momentum\n",
    "        \n",
    "        loss_history = loss_hist\n",
    "        train_history = train_hist\n",
    "        val_history = val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2dd065839a0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
